{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJu8oFs86FjF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPEN_API_KEY\" # 5$ karcha karna padega boss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Fe61XA69FR"
      },
      "source": [
        "## Wikipedia Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Wikipedia Retriever is a retriever that queries the wikipedia API to fetch relevant content for a given query\n",
        "\n",
        "## How it works\n",
        "\n",
        "1. You give it a query\n",
        "2. It send the query to wikipedia API\n",
        "3. It receives the most relevant articles\n",
        "4. It returns them as Langchain `document` Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tVlVrUuQ6cCC"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import WikipediaRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q5FUCNmX7ICr"
      },
      "outputs": [],
      "source": [
        "# Initialize the retriever (optional: set language and top_k)\n",
        "retriever = WikipediaRetriever(top_k_results=2, lang=\"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i-8sH-w67K8J"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define your query\n",
        "query = \"What are the latest new about artificial intelligence?\"\n",
        "\n",
        "# Get relevant Wikipedia documents\n",
        "docs = retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mD3zUptQSQg",
        "outputId": "e4963f93-dce0-4d6e-c955-4499196aa0f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, Mistral AI, DeepSeek, Baidu and Yandex.\\nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}, page_content='Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, Mistral AI, DeepSeek, Baidu and Yandex.\\nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nThe first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.\\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\\n\\n\\n=== Generative neural networks (2014–2019) ===\\n\\nMachine learning uses both discriminative models and generative models to predict data. Beginning in the late 2000s, the introduction of deep learning technology led to improvements in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images, '),\n",
              " Document(metadata={'title': 'Artificial intelligence controversies', 'summary': 'There have been many debates on the societal effects of artificial intelligence (AI), particularly in the late 2010s and 2020s, beginning with the accelerated period of development known as the AI boom. Advocates of AI have emphasized its potential to solve complex problems and improve the quality of life of humans. Detractors have argued that AI presents dangers and challenges involving ethics, plagiarism and theft, fraud, safety and alignment, environment impacts, unemployment, misinformation, artificial superintelligence and existential risks.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_controversies'}, page_content='There have been many debates on the societal effects of artificial intelligence (AI), particularly in the late 2010s and 2020s, beginning with the accelerated period of development known as the AI boom. Advocates of AI have emphasized its potential to solve complex problems and improve the quality of life of humans. Detractors have argued that AI presents dangers and challenges involving ethics, plagiarism and theft, fraud, safety and alignment, environment impacts, unemployment, misinformation, artificial superintelligence and existential risks.\\n\\n\\n== Pre-2020 ==\\n\\n\\n=== Microsoft Tay chatbot (2016) ===\\n\\nOn March 23, 2016, Microsoft released Tay, a chatbot designed to mimic the language patterns of a 19-year-old American girl and learn from interactions with Twitter users. Soon after its launch, Tay began posting racist, sexist, and otherwise inflammatory tweets after Twitter users deliberately taught it offensive phrases and exploited its \"repeat after me\" capability. Examples of controversial outputs included Holocaust denial and calls for genocide using racial slurs. Within 16 hours of its release, Microsoft suspended the Twitter acount, deleted the offensive tweets, and stated that Tay had suffered from a \"coordinated attack by a subset of people\" that \"exploited a vulnerability.\" Tay was briefly and accidentally re-released on March 30 during testing, after which it was permanently shut down. Microsoft CEO Satya Nadella later stated that Tay \"has had a great influence on how Microsoft is approaching AI\" and taught the company the importance of taking accountability.\\n\\n\\n== 2020–2024 ==\\n\\n\\n=== Voiceverse NFT plagiarism scandal (2022) ===\\n\\nOn January 14, 2022, voice actor Troy Baker announced a partnership with Voiceverse, a blockchain-based company that marketed proprietary AI voice cloning technology as non-fungible tokens (NFT), triggering immediate backlash over environmental concerns, fears that AI could displace human voice actors, and concerns about fraud. Later that same day, the pseudonymous creator of 15.ai—a free, non-commercial AI voice synthesis research project—revealed through server logs that Voiceverse had used 15.ai to generate voice samples, pitch-shifted them to make them unrecognizable, and falsely marketed them as their own proprietary technology before selling them as NFTs; the developer of 15.ai had previously stated that they had no interest in incorporating NFTs into their work. Voiceverse confessed within an hour and stated that their marketing team had used 15.ai without attribution while rushing to create a demo. News publications and AI watchdog groups universally characterized the incident as theft stemming from generative artificial intelligence.\\n\\n\\n=== Théâtre D\\'opéra Spatial (2022) ===\\n\\nOn August 29, 2022, Jason Michael Allen won first place in the \"emerging artist\" (non-professional) division of the \"Digital Arts/Digitally-Manipulated Photography\" category of the Colorado State Fair\\'s fine arts competition with Théâtre D\\'opéra Spatial, a digital artwork created using the AI image generator Midjourney, Adobe Photoshop, and AI upscaling tools, becoming one of the first images made using generative AI to win such a prize. Allen disclosed his use of Midjourney when submitting, though the judges did not know it was an AI tool but stated they would have awarded him first place regardless. While there was little contention about the image at the fair, reactions to the win on social media were negative. On September 5, 2023, the United States Copyright Office ruled that the work was not eligible for copyright protection as the human creative input was de minimis and that copyright rules \"exclude works produced by non-humans.\"\\n\\n\\n=== Statements on AI risk (2023) ===\\n\\nOn March 22, 2023, the Future of Life Institute published an open letter calling on \"all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4\", citing risks such as AI-generated propaganda, ex')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH3lPwDi7Myp",
        "outputId": "156011e5-ff17-4cfc-ec82-b7621f814f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "Content:\n",
            "Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\n",
            "Generative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, Mistral AI, DeepSeek, Baidu and Yandex.\n",
            "Generative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \n",
            "Generative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\n",
            "\n",
            "\n",
            "== History ==\n",
            "\n",
            "\n",
            "=== Early history ===\n",
            "The first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.\n",
            "Computers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\n",
            "The terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\n",
            "\n",
            "\n",
            "=== Generative neural networks (2014–2019) ===\n",
            "\n",
            "Machine learning uses both discriminative models and generative models to predict data. Beginning in the late 2000s, the introduction of deep learning technology led to improvements in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.\n",
            "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images, ...\n",
            "\n",
            "--- Result 2 ---\n",
            "Content:\n",
            "There have been many debates on the societal effects of artificial intelligence (AI), particularly in the late 2010s and 2020s, beginning with the accelerated period of development known as the AI boom. Advocates of AI have emphasized its potential to solve complex problems and improve the quality of life of humans. Detractors have argued that AI presents dangers and challenges involving ethics, plagiarism and theft, fraud, safety and alignment, environment impacts, unemployment, misinformation, artificial superintelligence and existential risks.\n",
            "\n",
            "\n",
            "== Pre-2020 ==\n",
            "\n",
            "\n",
            "=== Microsoft Tay chatbot (2016) ===\n",
            "\n",
            "On March 23, 2016, Microsoft released Tay, a chatbot designed to mimic the language patterns of a 19-year-old American girl and learn from interactions with Twitter users. Soon after its launch, Tay began posting racist, sexist, and otherwise inflammatory tweets after Twitter users deliberately taught it offensive phrases and exploited its \"repeat after me\" capability. Examples of controversial outputs included Holocaust denial and calls for genocide using racial slurs. Within 16 hours of its release, Microsoft suspended the Twitter acount, deleted the offensive tweets, and stated that Tay had suffered from a \"coordinated attack by a subset of people\" that \"exploited a vulnerability.\" Tay was briefly and accidentally re-released on March 30 during testing, after which it was permanently shut down. Microsoft CEO Satya Nadella later stated that Tay \"has had a great influence on how Microsoft is approaching AI\" and taught the company the importance of taking accountability.\n",
            "\n",
            "\n",
            "== 2020–2024 ==\n",
            "\n",
            "\n",
            "=== Voiceverse NFT plagiarism scandal (2022) ===\n",
            "\n",
            "On January 14, 2022, voice actor Troy Baker announced a partnership with Voiceverse, a blockchain-based company that marketed proprietary AI voice cloning technology as non-fungible tokens (NFT), triggering immediate backlash over environmental concerns, fears that AI could displace human voice actors, and concerns about fraud. Later that same day, the pseudonymous creator of 15.ai—a free, non-commercial AI voice synthesis research project—revealed through server logs that Voiceverse had used 15.ai to generate voice samples, pitch-shifted them to make them unrecognizable, and falsely marketed them as their own proprietary technology before selling them as NFTs; the developer of 15.ai had previously stated that they had no interest in incorporating NFTs into their work. Voiceverse confessed within an hour and stated that their marketing team had used 15.ai without attribution while rushing to create a demo. News publications and AI watchdog groups universally characterized the incident as theft stemming from generative artificial intelligence.\n",
            "\n",
            "\n",
            "=== Théâtre D'opéra Spatial (2022) ===\n",
            "\n",
            "On August 29, 2022, Jason Michael Allen won first place in the \"emerging artist\" (non-professional) division of the \"Digital Arts/Digitally-Manipulated Photography\" category of the Colorado State Fair's fine arts competition with Théâtre D'opéra Spatial, a digital artwork created using the AI image generator Midjourney, Adobe Photoshop, and AI upscaling tools, becoming one of the first images made using generative AI to win such a prize. Allen disclosed his use of Midjourney when submitting, though the judges did not know it was an AI tool but stated they would have awarded him first place regardless. While there was little contention about the image at the fair, reactions to the win on social media were negative. On September 5, 2023, the United States Copyright Office ruled that the work was not eligible for copyright protection as the human creative input was de minimis and that copyright rules \"exclude works produced by non-humans.\"\n",
            "\n",
            "\n",
            "=== Statements on AI risk (2023) ===\n",
            "\n",
            "On March 22, 2023, the Future of Life Institute published an open letter calling on \"all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4\", citing risks such as AI-generated propaganda, ex...\n"
          ]
        }
      ],
      "source": [
        "# Print retrieved content\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(f\"Content:\\n{doc.page_content}...\")  # truncate for display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2qt9J157djt"
      },
      "source": [
        "## Vector Store Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Vector store retriever in langchain is the most common type of retriever that lets you search and getch documents from a vectore store based on semantic similarity suing vector embeddings.\n",
        "\n",
        "## How it works\n",
        "\n",
        "1. You store your documents in a vector store (like FAISS, CHROMA, Weaviate)\n",
        "2. Each document is converted into a dense vector using an embedding model\n",
        "3. When the user enters a query\n",
        "    - It's also turnd into a vector\n",
        "    - The retriever compares the query vector with the stored vectors\n",
        "    - it retrieves the top-k-most similar ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sUKzoti97OKc"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dLymTTcA7nbZ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Your source documents\n",
        "documents = [\n",
        "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
        "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
        "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
        "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B5J0HYsr7prG"
      },
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m embedding_model = OpenAIEmbeddings()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Step 3: Create Chroma vector store in memory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m vectorstore = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy_collection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m    838\u001b[39m         api=chroma_collection._client,\n\u001b[32m    839\u001b[39m         ids=ids,\n\u001b[32m    840\u001b[39m         metadatas=metadatas,\n\u001b[32m    841\u001b[39m         documents=texts,\n\u001b[32m    842\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    281\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:591\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    590\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:479\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    483\u001b[39m         response = response.model_dump()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\src\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "# Step 2: Initialize embedding model\n",
        "load_dotenv()  # Load environment variables from .env file if needed\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "\n",
        "# Step 3: Create Chroma vector store in memory\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embedding_model,\n",
        "    collection_name=\"my_collection\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvSgoUYs7sLu"
      },
      "outputs": [],
      "source": [
        "# Step 4: Convert vectorstore into a retriever\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5l0rXl67v4N"
      },
      "outputs": [],
      "source": [
        "query = \"What is Chroma used for?\"\n",
        "results = retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMAEeCxK7yRR",
        "outputId": "7f140c90-bf2d-4d54-8988-813b74ed281b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "Chroma is a vector database optimized for LLM-based search.\n",
            "\n",
            "--- Result 2 ---\n",
            "LangChain helps developers build LLM applications easily.\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh0zC7L6R1Zn"
      },
      "outputs": [],
      "source": [
        "results = vectorstore.similarity_search(query, k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7kYMau5R1sC",
        "outputId": "d7b05617-45d7-4584-d18a-a578e4a28e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "Chroma is a vector database optimized for LLM-based search.\n",
            "\n",
            "--- Result 2 ---\n",
            "LangChain helps developers build LLM applications easily.\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDwJT1x9A2tI"
      },
      "source": [
        "## MMR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uL8bET570ud"
      },
      "outputs": [],
      "source": [
        "# Sample documents\n",
        "docs = [\n",
        "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
        "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
        "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
        "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
        "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
        "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM7GvqKeA8ml"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Initialize OpenAI embeddings\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "\n",
        "# Step 2: Create the FAISS vector store from documents\n",
        "vectorstore = FAISS.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embedding_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueDg6SApBAqt"
      },
      "outputs": [],
      "source": [
        "# Enable MMR in the retriever\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\",                   # <-- This enables MMR\n",
        "    search_kwargs={\"k\": 3, \"lambda_mult\": 0.5}  # k = top results, lambda_mult = relevance-diversity balance\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52AkKNz7Chcf"
      },
      "outputs": [],
      "source": [
        "query = \"What is langchain?\"\n",
        "results = retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-HvthKyCkBL",
        "outputId": "6bec200b-9541-480f-fa94-1b8c6b3174f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "LangChain is used to build LLM based applications.\n",
            "\n",
            "--- Result 2 ---\n",
            "Embeddings are vector representations of text.\n",
            "\n",
            "--- Result 3 ---\n",
            "LangChain supports Chroma, FAISS, Pinecone, and more.\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFybBaL-Eu8-"
      },
      "source": [
        "## Multiquery Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djm-59wI1J-s"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxr_cxaJ1KQV"
      },
      "outputs": [],
      "source": [
        "# Relevant health & wellness documents\n",
        "all_docs = [\n",
        "    Document(page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
        "    Document(page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
        "    Document(page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
        "    Document(page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
        "    Document(page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
        "    Document(page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
        "    Document(page_content=\"Python balances readability with power, making it a popular system design language.\", metadata={\"source\": \"I2\"}),\n",
        "    Document(page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
        "    Document(page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
        "    Document(page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"}),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq6eouD41KfF"
      },
      "outputs": [],
      "source": [
        "# Initialize OpenAI embeddings\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "\n",
        "# Create FAISS vector store\n",
        "vectorstore = FAISS.from_documents(documents=all_docs, embedding=embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh62ZNvD1Krv"
      },
      "outputs": [],
      "source": [
        "# Create retrievers\n",
        "similarity_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXUHDW6m1K75"
      },
      "outputs": [],
      "source": [
        "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ybExIQQ1bnt"
      },
      "outputs": [],
      "source": [
        "# Query\n",
        "query = \"How to improve energy levels and maintain balance?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2SlmAoi1gOP"
      },
      "outputs": [],
      "source": [
        "# Retrieve results\n",
        "similarity_results = similarity_retriever.invoke(query)\n",
        "multiquery_results= multiquery_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUtMLupwfe2",
        "outputId": "743431a3-5b0e-4f69-8af3-dec66a49f7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
            "\n",
            "--- Result 2 ---\n",
            "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
            "\n",
            "--- Result 3 ---\n",
            "Regular walking boosts heart health and can reduce symptoms of depression.\n",
            "\n",
            "--- Result 4 ---\n",
            "Deep sleep is crucial for cellular repair and emotional regulation.\n",
            "\n",
            "--- Result 5 ---\n",
            "The solar energy system in modern homes helps balance electricity demand.\n",
            "******************************************************************************************************************************************************\n",
            "\n",
            "--- Result 1 ---\n",
            "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
            "\n",
            "--- Result 2 ---\n",
            "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
            "\n",
            "--- Result 3 ---\n",
            "Regular walking boosts heart health and can reduce symptoms of depression.\n",
            "\n",
            "--- Result 4 ---\n",
            "Consuming leafy greens and fruits helps detox the body and improve longevity.\n",
            "\n",
            "--- Result 5 ---\n",
            "Deep sleep is crucial for cellular repair and emotional regulation.\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(similarity_results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)\n",
        "\n",
        "print(\"*\"*150)\n",
        "\n",
        "for i, doc in enumerate(multiquery_results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AP7o9-VJ0Zq"
      },
      "source": [
        "## ContextualCompressionRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVl6n3HH6gp_"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmLD6aZB6g1k"
      },
      "outputs": [],
      "source": [
        "# Recreate the document objects from the previous data\n",
        "docs = [\n",
        "    Document(page_content=(\n",
        "        \"\"\"The Grand Canyon is one of the most visited natural wonders in the world.\n",
        "        Photosynthesis is the process by which green plants convert sunlight into energy.\n",
        "        Millions of tourists travel to see it every year. The rocks date back millions of years.\"\"\"\n",
        "    ), metadata={\"source\": \"Doc1\"}),\n",
        "\n",
        "    Document(page_content=(\n",
        "        \"\"\"In medieval Europe, castles were built primarily for defense.\n",
        "        The chlorophyll in plant cells captures sunlight during photosynthesis.\n",
        "        Knights wore armor made of metal. Siege weapons were often used to breach castle walls.\"\"\"\n",
        "    ), metadata={\"source\": \"Doc2\"}),\n",
        "\n",
        "    Document(page_content=(\n",
        "        \"\"\"Basketball was invented by Dr. James Naismith in the late 19th century.\n",
        "        It was originally played with a soccer ball and peach baskets. NBA is now a global league.\"\"\"\n",
        "    ), metadata={\"source\": \"Doc3\"}),\n",
        "\n",
        "    Document(page_content=(\n",
        "        \"\"\"The history of cinema began in the late 1800s. Silent films were the earliest form.\n",
        "        Thomas Edison was among the pioneers. Photosynthesis does not occur in animal cells.\n",
        "        Modern filmmaking involves complex CGI and sound design.\"\"\"\n",
        "    ), metadata={\"source\": \"Doc4\"})\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgMNKHnv6hD8"
      },
      "outputs": [],
      "source": [
        "# Create a FAISS vector store from the documents\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(docs, embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlAqc8lQrz_B"
      },
      "outputs": [],
      "source": [
        "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHjUdgiS6hRK"
      },
      "outputs": [],
      "source": [
        "# Set up the compressor using an LLM\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "compressor = LLMChainExtractor.from_llm(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um5gKEMT6hdB"
      },
      "outputs": [],
      "source": [
        "# Create the contextual compression retriever\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_retriever=base_retriever,\n",
        "    base_compressor=compressor\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmHGenTo6hp6"
      },
      "outputs": [],
      "source": [
        "# Query the retriever\n",
        "query = \"What is photosynthesis?\"\n",
        "compressed_results = compression_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyIUYw035g0c",
        "outputId": "99a654d5-9239-4912-fd3e-4130c00b115a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "Photosynthesis is the process by which green plants convert sunlight into energy.\n",
            "\n",
            "--- Result 2 ---\n",
            "The chlorophyll in plant cells captures sunlight during photosynthesis.\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(compressed_results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "src",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
